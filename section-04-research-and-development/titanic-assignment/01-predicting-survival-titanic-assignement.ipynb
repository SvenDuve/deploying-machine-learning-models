{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting Survival on the Titanic\n",
    "\n",
    "### History\n",
    "Perhaps one of the most infamous shipwrecks in history, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 people on board. Interestingly, by analysing the probability of survival based on few attributes like gender, age, and social status, we can make very accurate predictions on which passengers would survive. Some groups of people were more likely to survive than others, such as women, children, and the upper-class. Therefore, we can learn about the society priorities and privileges at the time.\n",
    "\n",
    "### Assignment:\n",
    "\n",
    "Build a Machine Learning Pipeline, to engineer the features in the data set and predict who is more likely to Survive the catastrophe.\n",
    "\n",
    "Follow the Jupyter notebook below, and complete the missing bits of code, to achieve each one of the pipeline steps."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "source": [
    "import re\n",
    "\n",
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to divide train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# to build the models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# to evaluate the models\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# to persist the model and the scaler\n",
    "import joblib\n",
    "\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare the data set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "source": [
    "# load the data - it is available open source and online\n",
    "\n",
    "data = pd.read_csv('https://www.openml.org/data/get_csv/16826755/phpMYEkMl')\n",
    "\n",
    "# display data\n",
    "data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>?</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>?</td>\n",
       "      <td>135</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "      age  sibsp  parch  ticket      fare    cabin embarked boat body  \\\n",
       "0      29      0      0   24160  211.3375       B5        S    2    ?   \n",
       "1  0.9167      1      2  113781    151.55  C22 C26        S   11    ?   \n",
       "2       2      1      2  113781    151.55  C22 C26        S    ?    ?   \n",
       "3      30      1      2  113781    151.55  C22 C26        S    ?  135   \n",
       "4      25      1      2  113781    151.55  C22 C26        S    ?    ?   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "metadata": {},
     "execution_count": 261
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "source": [
    "# replace interrogation marks by NaN values\n",
    "\n",
    "data = data.replace('?', np.nan)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# retain only the first cabin if more than\n",
    "# 1 are available per passenger\n",
    "\n",
    "def get_first_cabin(row):\n",
    "    try:\n",
    "        return row.split()[0]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "data['cabin'] = data['cabin'].apply(get_first_cabin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "source": [
    "# extracts the title (Mr, Ms, etc) from the name variable\n",
    "\n",
    "def get_title(passenger):\n",
    "    line = passenger\n",
    "    if re.search('Mrs', line):\n",
    "        return 'Mrs'\n",
    "    elif re.search('Mr', line):\n",
    "        return 'Mr'\n",
    "    elif re.search('Miss', line):\n",
    "        return 'Miss'\n",
    "    elif re.search('Master', line):\n",
    "        return 'Master'\n",
    "    else:\n",
    "        return 'Other'\n",
    "    \n",
    "data['title'] = data['name'].apply(get_title)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "source": [
    "# cast numerical variables as floats\n",
    "\n",
    "data['fare'] = data['fare'].astype('float')\n",
    "data['age'] = data['age'].astype('float')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "source": [
    "# drop unnecessary variables\n",
    "\n",
    "data.drop(labels=['name','ticket', 'boat', 'body','home.dest'], axis=1, inplace=True)\n",
    "\n",
    "# display data\n",
    "data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>Master</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived     sex      age  sibsp  parch      fare    cabin  \\\n",
       "0       1         1  female  29.0000      0      0  211.3375       B5   \n",
       "1       1         1    male   0.9167      1      2  151.5500  C22 C26   \n",
       "2       1         0  female   2.0000      1      2  151.5500  C22 C26   \n",
       "3       1         0    male  30.0000      1      2  151.5500  C22 C26   \n",
       "4       1         0  female  25.0000      1      2  151.5500  C22 C26   \n",
       "\n",
       "  embarked   title  \n",
       "0        S    Miss  \n",
       "1        S  Master  \n",
       "2        S    Miss  \n",
       "3        S      Mr  \n",
       "4        S     Mrs  "
      ]
     },
     "metadata": {},
     "execution_count": 265
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "source": [
    "# save the data set\n",
    "\n",
    "data.to_csv('titanic.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Exploration\n",
    "\n",
    "### Find numerical and categorical variables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "source": [
    "target = 'survived'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "source": [
    "vars_num = [var for var in data.columns if data[var].dtype != object and var != target] # fill your code here\n",
    "\n",
    "vars_cat = [var for var in data.columns if data[var].dtype == object] # fill your code here\n",
    "\n",
    "print('Number of numerical variables: {}'.format(len(vars_num)))\n",
    "print('Number of categorical variables: {}'.format(len(vars_cat)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of numerical variables: 5\n",
      "Number of categorical variables: 4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Find missing values in variables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "source": [
    "# first in numerical variables\n",
    "missing_num = [var for var in vars_num if data[var].isnull().sum() > 0]\n",
    "data[missing_num].isnull().mean().sort_values(ascending=False)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "age     0.200917\n",
       "fare    0.000764\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 269
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "source": [
    "# now in categorical variables\n",
    "missing_cat = [var for var in vars_cat if data[var].isnull().sum() > 0]\n",
    "data[missing_cat].isnull().mean().sort_values(ascending=False)\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "cabin       0.774637\n",
       "embarked    0.001528\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 270
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Determine cardinality of categorical variables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "source": [
    "data[vars_cat].nunique().sort_values(ascending=False).plot.bar()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "metadata": {},
     "execution_count": 271
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Determine the distribution of numerical variables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "source": [
    "data[vars_num].hist()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'pclass'}>,\n",
       "        <AxesSubplot:title={'center':'age'}>],\n",
       "       [<AxesSubplot:title={'center':'sibsp'}>,\n",
       "        <AxesSubplot:title={'center':'parch'}>],\n",
       "       [<AxesSubplot:title={'center':'fare'}>, <AxesSubplot:>]],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 272
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Separate data into train and test\n",
    "\n",
    "Use the code below for reproducibility. Don't change it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('survived', axis=1),  # predictors\n",
    "    data['survived'],  # target\n",
    "    test_size=0.2,  # percentage of obs in test set\n",
    "    random_state=0)  # seed to ensure reproducibility\n",
    "\n",
    "X_train.shape, X_test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1047, 9), (262, 9))"
      ]
     },
     "metadata": {},
     "execution_count": 287
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### Extract only the letter (and drop the number) from the variable Cabin"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "source": [
    "X_train['cabin'] = X_train['cabin'].str.extract(r'([a-zA-Z])')\n",
    "X_test['cabin'] = X_test['cabin'].str.extract(r'([a-zA-Z])')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fill in Missing data in numerical variables:\n",
    "\n",
    "- Add a binary missing indicator\n",
    "- Fill NA in original variable with the median"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "source": [
    "for var in missing_num:\n",
    "    median = X_train[var].median()\n",
    "    print(var, median)\n",
    "#    X_train[var + '_na'] = np.where(X_train[var].isnull(), 1, 0)\n",
    "#    X_test[var + '_na'] = np.where(X_test[var].isnull(), 1, 0)\n",
    "\n",
    "    X_train[var].fillna(median, inplace=True)\n",
    "    X_test[var].fillna(median, inplace=True)\n",
    "#missing_num"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "age 28.0\n",
      "fare 14.4542\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "source": [
    "X_train[missing_num].isnull().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "age     0\n",
       "fare    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 290
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Replace Missing data in categorical variables with the string **Missing**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "source": [
    "missing_cat"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['cabin', 'embarked']"
      ]
     },
     "metadata": {},
     "execution_count": 291
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "source": [
    "X_train[missing_cat] = X_train[missing_cat].fillna('Missing')\n",
    "X_test[missing_cat] = X_test[missing_cat].fillna('Missing')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "source": [
    "X_train[missing_cat].isnull().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "cabin       0\n",
       "embarked    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 293
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove rare labels in categorical variables\n",
    "\n",
    "- remove labels present in less than 5 % of the passengers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "source": [
    "for var in vars_cat:\n",
    "    index = pd.Index(X_train[var])\n",
    "    remove_label = []\n",
    "    #print(index.value_counts())\n",
    "    for el in zip(index.value_counts(normalize=True).index.tolist(), index.value_counts(normalize=True)):\n",
    "        if el[1] < 0.05:\n",
    "            remove_label.append(el[0])\n",
    "    for label in remove_label:\n",
    "        print(label)\n",
    "        X_train[var] = X_train[var].where(X_train[var] != label, 'Missing')\n",
    "        X_test[var] = X_test[var].where(X_test[var] != label, 'Missing')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "B\n",
      "D\n",
      "E\n",
      "A\n",
      "F\n",
      "G\n",
      "T\n",
      "Missing\n",
      "Master\n",
      "Other\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "source": [
    "X_train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Missing</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>41.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>Missing</td>\n",
       "      <td>C</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Q</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>Missing</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>Missing</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5750</td>\n",
       "      <td>Missing</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Missing</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Q</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.7500</td>\n",
       "      <td>Missing</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.5000</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Q</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1047 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass     sex      age  sibsp  parch      fare    cabin embarked title\n",
       "1118       3    male  25.0000      0      0    7.9250  Missing        S    Mr\n",
       "44         1  female  41.0000      0      0  134.5000  Missing        C  Miss\n",
       "1072       3    male  28.0000      0      0    7.7333  Missing        Q    Mr\n",
       "1130       3  female  18.0000      0      0    7.7750  Missing        S  Miss\n",
       "574        2    male  29.0000      1      0   21.0000  Missing        S    Mr\n",
       "...      ...     ...      ...    ...    ...       ...      ...      ...   ...\n",
       "763        3  female   0.1667      1      2   20.5750  Missing        S  Miss\n",
       "835        3    male  28.0000      0      0    8.0500  Missing        S    Mr\n",
       "1216       3  female  28.0000      0      0    7.7333  Missing        Q  Miss\n",
       "559        2  female  20.0000      0      0   36.7500  Missing        S  Miss\n",
       "684        3  female  32.0000      1      1   15.5000  Missing        Q   Mrs\n",
       "\n",
       "[1047 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 295
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perform one hot encoding of categorical variables into k-1 binary variables\n",
    "\n",
    "- k-1, means that if the variable contains 9 different categories, we create 8 different binary variables\n",
    "- Remember to drop the original categorical variable (the one with the strings) after the encoding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "source": [
    "vars_cat"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['sex', 'cabin', 'embarked', 'title']"
      ]
     },
     "metadata": {},
     "execution_count": 296
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "source": [
    "for var in vars_cat:\n",
    "    X_train = X_train.join(pd.get_dummies(X_train[var].append(X_test[var]), prefix=var))\n",
    "    X_test = X_test.join(pd.get_dummies(X_train[var].append(X_test[var]), prefix=var))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "source": [
    "X_train = X_train.drop(columns=vars_cat)\n",
    "X_test = X_test.drop(columns=vars_cat)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "source": [
    "print(X_train.columns)\n",
    "print(X_test.columns)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['pclass', 'age', 'sibsp', 'parch', 'fare', 'sex_female', 'sex_male',\n",
      "       'cabin_C', 'cabin_Missing', 'embarked_C', 'embarked_Missing',\n",
      "       'embarked_Q', 'embarked_S', 'title_Miss', 'title_Missing', 'title_Mr',\n",
      "       'title_Mrs'],\n",
      "      dtype='object')\n",
      "Index(['pclass', 'age', 'sibsp', 'parch', 'fare', 'sex_female', 'sex_male',\n",
      "       'cabin_C', 'cabin_Missing', 'embarked_C', 'embarked_Missing',\n",
      "       'embarked_Q', 'embarked_S', 'title_Miss', 'title_Missing', 'title_Mr',\n",
      "       'title_Mrs'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scale the variables\n",
    "\n",
    "- Use the standard scaler from Scikit-learn"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "metadata": {},
     "execution_count": 300
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the Logistic Regression model\n",
    "\n",
    "- Set the regularization parameter to 0.0005\n",
    "- Set the seed to 0"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "source": [
    "clf = LogisticRegression(random_state=0).fit(scaler.transform(X_train), y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "source": [
    "clf.score(scaler.transform(X_test), y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8053435114503816"
      ]
     },
     "metadata": {},
     "execution_count": 304
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make predictions and evaluate model performance\n",
    "\n",
    "Determine:\n",
    "- roc-auc\n",
    "- accuracy\n",
    "\n",
    "**Important, remember that to determine the accuracy, you need the outcome 0, 1, referring to survived or not. But to determine the roc-auc you need the probability of survival.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "source": [
    "roc_auc_score(y_test, [clf.predict_proba(scaler.transform(X_test)[:,1])])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 0.66511788 -0.68870978  0.98366557 -0.13125133 -0.37016209 -2.04253743\n  1.46148709  1.78003477  2.17821938 -0.13125133 -0.13125133  0.7447548\n -2.30799118 -0.92762054 -0.68870978 -0.44979901  1.22257633  0.82439172\n  2.01894554  0.26693328 -0.60907285 -1.32580514 -0.13125133 -1.24616822\n -1.88326359  0.98366557 -0.84798362  0.42620712 -0.13125133 -1.24616822\n -2.04253743 -1.08689438 -0.44979901  1.26239479  1.70039785 -0.13125133\n  0.26693328 -0.13125133 -0.13125133 -0.44979901 -0.13125133  1.93930862\n  2.2578563  -2.12217435 -0.37016209 -2.20181127  0.38638866  1.22257633\n -2.32790041 -0.13125133 -1.00725746 -0.13125133 -0.44979901 -0.05161441\n -0.29052517 -0.13125133 -0.92762054  0.82439172 -0.60907285 -1.00725746\n -0.7683467   1.22257633 -1.64435283 -1.80362667 -2.20181127 -0.92762054\n -0.44979901 -0.13125133 -0.68870978 -0.92762054 -0.05161441  0.42620712\n -0.13125133  1.70039785 -0.13125133  0.18729636 -0.92762054  2.09858246\n -0.13125133 -0.13125133 -0.44979901 -1.96290051  0.10765943  0.98366557\n -0.13125133 -0.13125133  0.18729636  1.38185017 -0.13125133 -0.13125133\n -0.13125133 -0.13125133  0.98366557 -0.92762054 -0.13125133  1.30221325\n -1.24616822 -0.13125133 -0.68870978  0.66511788 -1.24616822 -0.92762054\n  0.26693328  0.02802251  0.02802251  0.82439172 -2.28808195 -0.13125133\n  0.42620712  1.38185017 -0.13125133  0.10765943 -0.92762054  1.54112401\n -0.60907285  1.38185017 -1.00725746  2.17821938  0.42620712 -0.44979901\n  1.46148709 -1.32580514 -0.13125133 -0.68870978  0.86421018 -0.13125133\n -0.13125133 -0.21088825  0.50584404 -0.21088825 -0.13125133 -0.13125133\n  1.38185017 -1.00725746  4.00986856 -0.60907285  2.57640398 -0.13125133\n -0.52943593 -0.13125133 -0.68870978  1.46148709 -0.68870978 -0.84798362\n  3.29313627 -0.13125133 -2.30135742 -0.13125133 -2.28144819 -0.13125133\n -2.12217435  2.73567783 -0.60907285 -1.80362667 -0.05161441 -0.13125133\n  3.69132088 -1.00725746  0.02802251 -1.1665313   0.38638866  1.38185017\n -0.13125133 -0.52943593 -0.37016209 -1.08689438 -0.13125133 -0.84798362\n  0.7447548  -0.40998055 -0.13125133  0.98366557 -0.13125133 -0.44979901\n  1.8596717   2.17821938 -0.7683467  -0.92762054 -0.7683467  -0.84798362\n  0.42620712 -0.13125133  0.7447548  -1.08689438  0.02802251 -0.13125133\n  1.93930862 -0.13125133  1.46148709 -1.08689438  0.82439172  0.7447548\n -0.13125133  2.17821938  0.50584404 -0.13125133  1.06330249 -0.37016209\n -0.52943593  0.3465702  -0.44979901 -0.13125133 -0.60907285  2.2578563\n  1.62076093 -0.84798362  1.06330249 -2.12217435 -1.00725746  0.3465702\n -0.13125133 -0.13125133 -0.52943593  1.70039785 -0.13125133  1.78003477\n  0.3465702   2.058764    0.22711482 -0.13125133 -0.60907285 -0.60907285\n -1.24616822  0.10765943  0.50584404  0.50584404 -0.13125133 -1.72398975\n -2.04253743 -1.1665313  -0.60907285  0.98366557 -0.37016209 -0.52943593\n -0.7683467  -0.21088825 -0.13125133  3.21349935 -0.72852824 -1.64435283\n  0.02802251 -1.00725746 -0.13125133 -0.13125133 -0.68870978 -2.28144819\n  0.02802251  1.22257633 -0.84798362 -1.72398975  0.02802251  0.06784097\n -2.29472367 -0.05161441  0.50584404 -0.13125133 -0.05161441 -0.60907285\n -0.13125133  0.02802251 -0.29052517 -0.13125133].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5c/rmctnwx57jg6qy39ggw37h700000gn/T/ipykernel_2148/4141226667.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/udemy/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1467\u001b[0m                                                 self.solver == 'liblinear')))\n\u001b[1;32m   1468\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0movr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1470\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m             \u001b[0mdecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/udemy/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_predict_proba_lr\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mmulticlass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mhandled\u001b[0m \u001b[0mby\u001b[0m \u001b[0mnormalizing\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mover\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \"\"\"\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0mexpit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/udemy/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/udemy/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/udemy/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    639\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 0.66511788 -0.68870978  0.98366557 -0.13125133 -0.37016209 -2.04253743\n  1.46148709  1.78003477  2.17821938 -0.13125133 -0.13125133  0.7447548\n -2.30799118 -0.92762054 -0.68870978 -0.44979901  1.22257633  0.82439172\n  2.01894554  0.26693328 -0.60907285 -1.32580514 -0.13125133 -1.24616822\n -1.88326359  0.98366557 -0.84798362  0.42620712 -0.13125133 -1.24616822\n -2.04253743 -1.08689438 -0.44979901  1.26239479  1.70039785 -0.13125133\n  0.26693328 -0.13125133 -0.13125133 -0.44979901 -0.13125133  1.93930862\n  2.2578563  -2.12217435 -0.37016209 -2.20181127  0.38638866  1.22257633\n -2.32790041 -0.13125133 -1.00725746 -0.13125133 -0.44979901 -0.05161441\n -0.29052517 -0.13125133 -0.92762054  0.82439172 -0.60907285 -1.00725746\n -0.7683467   1.22257633 -1.64435283 -1.80362667 -2.20181127 -0.92762054\n -0.44979901 -0.13125133 -0.68870978 -0.92762054 -0.05161441  0.42620712\n -0.13125133  1.70039785 -0.13125133  0.18729636 -0.92762054  2.09858246\n -0.13125133 -0.13125133 -0.44979901 -1.96290051  0.10765943  0.98366557\n -0.13125133 -0.13125133  0.18729636  1.38185017 -0.13125133 -0.13125133\n -0.13125133 -0.13125133  0.98366557 -0.92762054 -0.13125133  1.30221325\n -1.24616822 -0.13125133 -0.68870978  0.66511788 -1.24616822 -0.92762054\n  0.26693328  0.02802251  0.02802251  0.82439172 -2.28808195 -0.13125133\n  0.42620712  1.38185017 -0.13125133  0.10765943 -0.92762054  1.54112401\n -0.60907285  1.38185017 -1.00725746  2.17821938  0.42620712 -0.44979901\n  1.46148709 -1.32580514 -0.13125133 -0.68870978  0.86421018 -0.13125133\n -0.13125133 -0.21088825  0.50584404 -0.21088825 -0.13125133 -0.13125133\n  1.38185017 -1.00725746  4.00986856 -0.60907285  2.57640398 -0.13125133\n -0.52943593 -0.13125133 -0.68870978  1.46148709 -0.68870978 -0.84798362\n  3.29313627 -0.13125133 -2.30135742 -0.13125133 -2.28144819 -0.13125133\n -2.12217435  2.73567783 -0.60907285 -1.80362667 -0.05161441 -0.13125133\n  3.69132088 -1.00725746  0.02802251 -1.1665313   0.38638866  1.38185017\n -0.13125133 -0.52943593 -0.37016209 -1.08689438 -0.13125133 -0.84798362\n  0.7447548  -0.40998055 -0.13125133  0.98366557 -0.13125133 -0.44979901\n  1.8596717   2.17821938 -0.7683467  -0.92762054 -0.7683467  -0.84798362\n  0.42620712 -0.13125133  0.7447548  -1.08689438  0.02802251 -0.13125133\n  1.93930862 -0.13125133  1.46148709 -1.08689438  0.82439172  0.7447548\n -0.13125133  2.17821938  0.50584404 -0.13125133  1.06330249 -0.37016209\n -0.52943593  0.3465702  -0.44979901 -0.13125133 -0.60907285  2.2578563\n  1.62076093 -0.84798362  1.06330249 -2.12217435 -1.00725746  0.3465702\n -0.13125133 -0.13125133 -0.52943593  1.70039785 -0.13125133  1.78003477\n  0.3465702   2.058764    0.22711482 -0.13125133 -0.60907285 -0.60907285\n -1.24616822  0.10765943  0.50584404  0.50584404 -0.13125133 -1.72398975\n -2.04253743 -1.1665313  -0.60907285  0.98366557 -0.37016209 -0.52943593\n -0.7683467  -0.21088825 -0.13125133  3.21349935 -0.72852824 -1.64435283\n  0.02802251 -1.00725746 -0.13125133 -0.13125133 -0.68870978 -2.28144819\n  0.02802251  1.22257633 -0.84798362 -1.72398975  0.02802251  0.06784097\n -2.29472367 -0.05161441  0.50584404 -0.13125133 -0.05161441 -0.60907285\n -0.13125133  0.02802251 -0.29052517 -0.13125133].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "source": [
    "[clf.predict_proba(scaler.transform(X_test))[:,1]]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([0.06974097, 0.77303775, 0.10605762, 0.09249114, 0.22321735,\n",
       "        0.60307761, 0.26433772, 0.45908798, 0.09782803, 0.09085687,\n",
       "        0.31919143, 0.08710933, 0.58855813, 0.63554317, 0.92743915,\n",
       "        0.21706351, 0.68875995, 0.46149417, 0.93065631, 0.07967249,\n",
       "        0.10585554, 0.10256864, 0.09079133, 0.88779836, 0.48379309,\n",
       "        0.80218423, 0.24241851, 0.13255783, 0.10729404, 0.66031131,\n",
       "        0.80496107, 0.95288827, 0.78448615, 0.18190522, 0.86489047,\n",
       "        0.09072054, 0.07963775, 0.40448405, 0.15711712, 0.10077053,\n",
       "        0.0906382 , 0.10952409, 0.31606659, 0.57545661, 0.49154018,\n",
       "        0.16098043, 0.13369556, 0.94353598, 0.61250839, 0.09100927,\n",
       "        0.81533814, 0.09079978, 0.1007276 , 0.54761198, 0.09569066,\n",
       "        0.09084101, 0.93857522, 0.54114579, 0.64491505, 0.89242874,\n",
       "        0.1120948 , 0.64158296, 0.34653693, 0.47663463, 0.39328083,\n",
       "        0.7117154 , 0.21837183, 0.15711712, 0.10880182, 0.67081542,\n",
       "        0.8099063 , 0.07535244, 0.39189381, 0.04908119, 0.60460409,\n",
       "        0.94166543, 0.24772433, 0.88119128, 0.51630147, 0.1050344 ,\n",
       "        0.23624627, 0.71849185, 0.18488185, 0.29895586, 0.42696903,\n",
       "        0.95268517, 0.11053796, 0.05464141, 0.19312338, 0.10390671,\n",
       "        0.15711712, 0.15711712, 0.06279444, 0.14753057, 0.01644071,\n",
       "        0.4555424 , 0.13030216, 0.5229358 , 0.17121769, 0.90697999,\n",
       "        0.30393934, 0.07059615, 0.40582737, 0.61548194, 0.08656535,\n",
       "        0.11131557, 0.7181966 , 0.10523916, 0.07556681, 0.27965723,\n",
       "        0.40663226, 0.38664878, 0.28552716, 0.25847445, 0.60907581,\n",
       "        0.12689936, 0.29141357, 0.33845469, 0.17498425, 0.67136276,\n",
       "        0.41973573, 0.33846453, 0.54481585, 0.57611448, 0.0665933 ,\n",
       "        0.1050344 , 0.09080188, 0.09295867, 0.57542592, 0.32544445,\n",
       "        0.09080188, 0.54481585, 0.12537527, 0.45982495, 0.12667558,\n",
       "        0.1060435 , 0.09855941, 0.60451535, 0.10311472, 0.60488869,\n",
       "        0.2683038 , 0.91647579, 0.10895335, 0.11452853, 0.27159858,\n",
       "        0.26983481, 0.68183346, 0.09080188, 0.8730412 , 0.38937044,\n",
       "        0.42406361, 0.25163058, 0.22696945, 0.81246481, 0.15362414,\n",
       "        0.15711883, 0.64213392, 0.94087811, 0.14966958, 0.13384947,\n",
       "        0.08877629, 0.26936989, 0.31918862, 0.56354593, 0.11339873,\n",
       "        0.78572419, 0.1050344 , 0.11204393, 0.06790883, 0.09947855,\n",
       "        0.22528922, 0.30949973, 0.60462554, 0.10117497, 0.685009  ,\n",
       "        0.36772005, 0.11165212, 0.8993581 , 0.62100773, 0.96895185,\n",
       "        0.9826254 , 0.1050344 , 0.47844453, 0.26780232, 0.85121377,\n",
       "        0.6286173 , 0.91210109, 0.15711883, 0.12309081, 0.12393601,\n",
       "        0.79500168, 0.34869663, 0.95911275, 0.19513178, 0.33621675,\n",
       "        0.59230388, 0.08788627, 0.85200513, 0.10373443, 0.12951004,\n",
       "        0.13519053, 0.09084101, 0.10608843, 0.90478731, 0.26805936,\n",
       "        0.11444287, 0.12211181, 0.13213498, 0.12042501, 0.07759478,\n",
       "        0.60469899, 0.27287244, 0.22330648, 0.04912423, 0.77534468,\n",
       "        0.111234  , 0.12951004, 0.04343482, 0.22729246, 0.09058756,\n",
       "        0.89048214, 0.66702911, 0.92402328, 0.95207422, 0.75412432,\n",
       "        0.05249729, 0.51630147, 0.77390027, 0.65494762, 0.77905656,\n",
       "        0.81189949, 0.29912493, 0.09798386, 0.60086067, 0.11201072,\n",
       "        0.1179264 , 0.60458264, 0.06900304, 0.10999686, 0.31540163,\n",
       "        0.14967122, 0.21275847, 0.09264601, 0.19942424, 0.12548038,\n",
       "        0.32998219, 0.25604139, 0.2814044 , 0.77478049, 0.15529669,\n",
       "        0.08602025, 0.0850907 , 0.64656535, 0.08845669, 0.77941788,\n",
       "        0.15711712, 0.7601278 , 0.10608843, 0.09080188, 0.19042436,\n",
       "        0.20873981, 0.09084101])]"
      ]
     },
     "metadata": {},
     "execution_count": 325
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "That's it! Well done\n",
    "\n",
    "**Keep this code safe, as we will use this notebook later on, to build production code, in our next assignement!!**"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('udemy': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "interpreter": {
   "hash": "451160d8d49863236c1e2b8bff1505e4a2e2f673400ac37053faf27e036817ac"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}